[
  
  {
    "title": "Some ideas about gene essentiality prediction and graph neural network",
    "url": "/posts/About_Gene_Essentiality_prediction/",
    "categories": "Research, Sequence analysis",
    "tags": "gene essentiality",
    "date": "2021-11-11 19:38:09 +1100",
    





    "snippet": "What is the definition of gene essentiality (GE)?How to annotate it?Related publication resources.Previous studies of predicting GE.The feasibility of predicting GE using graph neural networks."
  },
  
  {
    "title": "Elegant way to use deep learning on Mac OS",
    "url": "/posts/The-way-to-deep-learning-with-AMD-GPU-on-Mac-OS/",
    "categories": "Research, Deep learning",
    "tags": "computational configuration",
    "date": "2018-11-12 09:38:09 +1100",
    





    "snippet": "Elegant way to use deep learning on Mac OS.Thanks to the Fabrice’s blog Deep Learning on a Mac with AMD GPUThe elegant solution for Deep Learning — PlaidMLMainstream deep learning frameworks, such as Tensorflow, PyTorch or Caffe 2, are not so friendly for Mac OS, especially for the AMD based Mac series.Among the solutions introduced in Fabrice’s blog, I think PlaidML is the most elegant one.The source code is a beginner quick guide based on PlaidML + Keras:#import the following two lines first!import plaidml.kerasplaidml.keras.install_backend()#Import libraries and modulesimport numpy as npnp.random.seed(123)  # for reproducibilityfrom keras.models import Sequentialfrom keras.layers import Dense, Dropout, Activation, Flattenfrom keras.layers import Convolution2D, MaxPooling2Dfrom keras.utils import np_utilsfrom keras.datasets import mnist#Load pre-shuffled MNIST data into train and test sets(X_train, y_train), (X_test, y_test) = mnist.load_data()#Preprocess input dataX_train = X_train.reshape(X_train.shape[0], 28, 28, 1)X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)X_train = X_train.astype(&#39;float32&#39;)X_test = X_test.astype(&#39;float32&#39;)X_train /= 255X_test /= 255#Preprocess class labelsY_train = np_utils.to_categorical(y_train, 10)Y_test = np_utils.to_categorical(y_test, 10)#Define model architecturemodel = Sequential()model.add(Convolution2D(32, (3, 3), activation=&#39;relu&#39;, input_shape=(28,28,1)))model.add(Convolution2D(32, (3, 3), activation=&#39;relu&#39;))model.add(MaxPooling2D(pool_size=(2,2)))model.add(Dropout(0.25))model.add(Flatten())model.add(Dense(128, activation=&#39;relu&#39;))model.add(Dropout(0.5))model.add(Dense(10, activation=&#39;softmax&#39;))#Compile modelmodel.compile(loss=&#39;categorical_crossentropy&#39;,              optimizer=&#39;adam&#39;,              metrics=[&#39;accuracy&#39;])#Fit model on training datamodel.fit(X_train, Y_train,          batch_size=32, nb_epoch=10, verbose=1)#Evaluate model on test datascore = model.evaluate(X_test, Y_test, verbose=0)print(score)"
  }
  
]

